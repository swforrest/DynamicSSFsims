---
title: "Step selection model fitting - static model"
subtitle:  "TwoStep approach fitted to 10 individuals with exponentially sampled random step lengths, without temporally dynamic parameters"
author: "Scott Forrest"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load packages

```{r message = FALSE, warning = FALSE}

options(scipen=999)

library(tidyverse)
packages <- c("lubridate", "survival", "terra", "raster", "tictoc", "TwoStepCLogit", "ecospat", "beepr", "clogitL1", "ggpubr", "MASS")
walk(packages, require, character.only = T)

```

Importing buffalo data with population level movement parameters

```{r}

buffalo_data_all <- read_csv("outputs/buffalo_popn_EvM_covs_STmemory1000_2023-10-05.csv")

buffalo_data_all <- buffalo_data_all %>% mutate(t1_ = lubridate::with_tz(buffalo_data_all$t1_, tzone = "Australia/Darwin"),
                                                t2_ = lubridate::with_tz(buffalo_data_all$t2_, tzone = "Australia/Darwin"))

buffalo_CLR <- buffalo_data_all %>%
  mutate(id_num = as.numeric(factor(id)), 
         step_id = step_id_, 
         x1 = x1_, x2 = x2_, 
         y1 = y1_, y2 = y2_, 
         t1 = t1_, 
         t1_rounded = round_date(t1_, "hour"), 
         hour_t1 = hour(t1_rounded),
         t2 = t2_, 
         t2_rounded = round_date(t2_, "hour"), 
         hour_t2 = hour(t2_rounded),
         hour = hour_t2,
         yday = yday(t1_),
         year = year(t1_), 
         month = month(t1_),
         sl = sl_, 
         log_sl = log(sl_), 
         ta = ta_, 
         cos_ta = cos(ta_),
         canopy_01 = canopy_cover/100,
         wofs0_20 = ifelse(WOFS > 20, 20, WOFS),
         spatiotemporal_memory_density_log = spatial_temporal_memory_density,
         spatiotemporal_memory_density = exp(spatial_temporal_memory_density),
         yday_s1 = sin(2*pi*yday/365),
         yday_s2 = sin(4*pi*yday/365),
         yday_s3 = sin(6*pi*yday/365),
         yday_s4 = sin(8*pi*yday/365),
         yday_c1 = cos(2*pi*yday/365),
         yday_c2 = cos(4*pi*yday/365),
         yday_c3 = cos(6*pi*yday/365),
         yday_c4 = cos(8*pi*yday/365),
         hour_s1 = sin(2*pi*hour/24),
         hour_s2 = sin(4*pi*hour/24),
         hour_s3 = sin(6*pi*hour/24),
         hour_s4 = sin(8*pi*hour/24),
         hour_c1 = cos(2*pi*hour/24),
         hour_c2 = cos(4*pi*hour/24),
         hour_c3 = cos(6*pi*hour/24),
         hour_c4 = cos(8*pi*hour/24))

# Filtering by animals that have more than a year of consistent data
buffalo_CLR %>% ggplot(aes(x = t1, y = factor(id), colour = factor(id))) +
  geom_point(alpha = 0.1) +
  scale_y_discrete("Buffalo ID") +
  scale_x_datetime("Date") +
  scale_colour_viridis_d() +
  theme_bw() +
  theme(legend.position = "none")

buffalo_year_ids <- c(2005, 2014, 2018, 2022, 2024, 2154, 2158, 2327, 2354, 2387)
buffalo_CLR_year <- buffalo_CLR %>% filter(id %in% buffalo_year_ids)
buffalo_CLR_year_harmonics <- buffalo_CLR_year %>% filter(t1 < "2019-07-25 09:32:42 ACST")

buffalo_data_all <- buffalo_CLR_year_harmonics

ggplot() +
  geom_density(data = buffalo_data_all %>% filter(y == 1), aes(x = log_sl, fill = factor(id)), alpha = 0.1) +
  geom_density(data = buffalo_data_all %>% filter(y == 0), aes(x = log_sl), colour = "red") +
  ggtitle("Used vs random steps") +
  theme_classic()

ggplot() +
  geom_density(data = buffalo_data_all %>% filter(y == 0), aes(x = log_sl, fill = factor(id)), alpha = 0.1) +
  ggtitle("Random steps") +
  theme_classic()

hist(buffalo_data_all$spatiotemporal_memory_density, breaks = 100)
hist(buffalo_data_all |> filter(spatiotemporal_memory_density_log > -20) |> pull(spatiotemporal_memory_density_log), breaks = 100)
mean(buffalo_data_all$spatiotemporal_memory_density_log, na.rm = T)
sd(buffalo_data_all$spatiotemporal_memory_density_log, na.rm = T)

```

Creating the data matrix

```{r}

buffalo_ids <- unique(buffalo_data_all$id)
months_wet <- c(1:4, 11:12)

# buffalo_data <- buffalo_data_all %>% filter(month %in% months_wet) # wet season
buffalo_data <- buffalo_data_all %>% filter(!month %in% months_wet) # dry season

buffalo_data_matrix_unscaled <- buffalo_data %>% transmute(
  
  ndvi = ndvi_temporal,
  ndvi_s1 = ndvi_temporal * hour_s1,
  ndvi_s2 = ndvi_temporal * hour_s2,
  ndvi_c1 = ndvi_temporal * hour_c1,
  ndvi_c2 = ndvi_temporal * hour_c2,
  
  ndvi_sq = ndvi_temporal ^ 2,
  ndvi_sq_s1 = (ndvi_temporal ^ 2) * hour_s1,
  ndvi_sq_s2 = (ndvi_temporal ^ 2) * hour_s2,
  ndvi_sq_c1 = (ndvi_temporal ^ 2) * hour_c1,
  ndvi_sq_c2 = (ndvi_temporal ^ 2) * hour_c2,
  
  canopy = canopy_01,
  canopy_s1 = canopy_01 * hour_s1,
  canopy_s2 = canopy_01 * hour_s2,
  canopy_c1 = canopy_01 * hour_c1,
  canopy_c2 = canopy_01 * hour_c2,
  
  canopy_sq = canopy_01 ^ 2,
  canopy_sq_s1 = (canopy_01 ^ 2) * hour_s1,
  canopy_sq_s2 = (canopy_01 ^ 2) * hour_s2,
  canopy_sq_c1 = (canopy_01 ^ 2) * hour_c1,
  canopy_sq_c2 = (canopy_01 ^ 2) * hour_c2,
  
  wofs = wofs0_20,
  wofs_s1 = wofs0_20 * hour_s1,
  wofs_s2 = wofs0_20 * hour_s2,
  wofs_c1 = wofs0_20 * hour_c1,
  wofs_c2 = wofs0_20 * hour_c2,
  
  slope = slope,
  slope_s1 = slope * hour_s1,
  slope_s2 = slope * hour_s2,
  slope_c1 = slope * hour_c1,
  slope_c2 = slope * hour_c2,
  
  herby = veg_herby,
  herby_s1 = veg_herby * hour_s1,
  herby_s2 = veg_herby * hour_s2,
  herby_c1 = veg_herby * hour_c1,
  herby_c2 = veg_herby * hour_c2,
  
  spatial_memory = spatiotemporal_memory_density,
  spatial_memory_s1 = spatiotemporal_memory_density * hour_s1,
  spatial_memory_s2 = spatiotemporal_memory_density * hour_s2,
  spatial_memory_c1 = spatiotemporal_memory_density * hour_c1,
  spatial_memory_c2 = spatiotemporal_memory_density * hour_c2,
  
  # spatial_memory = spatiotemporal_memory_density_log,
  # spatial_memory_s1 = spatiotemporal_memory_density_log * hour_s1,
  # spatial_memory_s2 = spatiotemporal_memory_density_log * hour_s2,
  # spatial_memory_c1 = spatiotemporal_memory_density_log * hour_c1,
  # spatial_memory_c2 = spatiotemporal_memory_density_log * hour_c2,
  
  step_l = sl,
  step_l_s1 = sl * hour_s1,
  step_l_s2 = sl * hour_s2,
  step_l_c1 = sl * hour_c1,
  step_l_c2 = sl * hour_c2,
  
  step_sqrt_l = sqrt(sl),
  step_sqrt_l_s1 = sqrt(sl) * hour_s1,
  step_sqrt_l_s2 = sqrt(sl) * hour_s2,
  step_sqrt_l_c1 = sqrt(sl) * hour_c1,
  step_sqrt_l_c2 = sqrt(sl) * hour_c2,

  cos_turn_a = cos_ta,
  cos_turn_a_s1 = cos_ta * hour_s1,
  cos_turn_a_s2 = cos_ta * hour_s2,
  cos_turn_a_c1 = cos_ta * hour_c1,
  cos_turn_a_c2 = cos_ta * hour_c2)

buffalo_data_matrix_scaled <- scale(buffalo_data_matrix_unscaled)
# buffalo_data_matrix_scaled <- scale(buffalo_data_matrix_unscaled, center = TRUE, scale = FALSE)
# buffalo_data_matrix_scaled <- buffalo_data_matrix_unscaled

mean_vals <- attr(buffalo_data_matrix_scaled, "scaled:center")
sd_vals <- attr(buffalo_data_matrix_scaled, "scaled:scale")
scaling_attributes <- data.frame(variable = names(buffalo_data_matrix_unscaled), mean = mean_vals, sd = sd_vals)

buffalo_data_scaled <- data.frame(id = buffalo_data$id,  step_id = buffalo_data$step_id, y = buffalo_data$y, buffalo_data_matrix_scaled)

```

Formula with two pairs of harmonics

```{r}

formula_twostep <- y ~ 
  
  ndvi +
  ndvi_s1 +
  ndvi_s2 +
  ndvi_c1 +
  ndvi_c2 +
  
  ndvi_sq +
  ndvi_sq_s1 +
  ndvi_sq_s2 +
  ndvi_sq_c1 +
  ndvi_sq_c2 +
  
  canopy +
  canopy_s1 +
  canopy_s2 +
  canopy_c1 +
  canopy_c2 +
  
  canopy_sq +
  canopy_sq_s1 +
  canopy_sq_s2 +
  canopy_sq_c1 +
  canopy_sq_c2 +
  
  wofs +
  wofs_s1 +
  wofs_s2 +
  wofs_c1 +
  wofs_c2 +
  
  slope +
  slope_s1 +
  slope_s2 +
  slope_c1 +
  slope_c2 +
  
  herby +
  herby_s1 +
  herby_s2 +
  herby_c1 +
  herby_c2 +

  spatial_memory +
  spatial_memory_s1 +
  spatial_memory_s2 +
  spatial_memory_c1 +
  spatial_memory_c2 +
  
  step_l +
  step_l_s1 +
  step_l_s2 +
  step_l_c1 +
  step_l_c2 +
  
  step_sqrt_l +
  step_sqrt_l_s1 +
  step_sqrt_l_s2 +
  step_sqrt_l_c1 +
  step_sqrt_l_c2 +

  cos_turn_a +
  cos_turn_a_s1 +
  cos_turn_a_s2 +
  cos_turn_a_c1 +
  cos_turn_a_c2 +
  
  strata(step_id) +
  cluster(id)

```

Fitting the model

```{r twostep model fit}

tic()
model_twostep_2p_harms <- Ts.estim(formula = formula_twostep,
         data = buffalo_data_scaled,
         all.m.1 = TRUE,
         D = "UN(1)",
         itermax = 10000)
toc()

# model_twostep_2p_harms
model_twostep_2p_harms$beta
model_twostep_2p_harms$se
# model_twostep_2p_harms$vcov
# diag(model_twostep_2p_harms$D) # between cluster variance
# model_twostep_2p_harms$r.effect # individual estimates

# hist(model_twostep_2p_harms$r.effect[,6])

coefs_clr <- data.frame(coefs = names(model_twostep_2p_harms$beta), value = model_twostep_2p_harms$beta)
coefs_clr$scale_sd <- scaling_attributes$sd
coefs_clr <- coefs_clr %>% mutate(value_nat = value / scale_sd)
head(coefs_clr)

beep(sound = 2)

# model_twostep_2p_harms$se / (scaling_attributes$sd)^2
# scaled_vcov
# scaled_vcov <- model_twostep_2p_harms$vcov / outer(scaling_attributes$sd, scaling_attributes$sd)

```

Reconstructing coefficients with two pairs of harmonics, with quadratic terms

```{r}

# hour <- seq(0.1,24,0.1)
hour <- seq(1,24,1)

hour_harmonics_df <- data.frame("linear_term" = rep(1, length(hour)),
                                "hour_s1" = sin(2*pi*hour/24),
                                "hour_s2" = sin(4*pi*hour/24),
                                "hour_c1" = cos(2*pi*hour/24),
                                "hour_c2" = cos(4*pi*hour/24))

harmonics_scaled_df <- data.frame(
  "hour" = hour,
  "ndvi" = as.numeric(coefs_clr %>% dplyr::filter(grepl("ndvi", coefs) & !grepl("sq", coefs)) %>% 
                        pull(value) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "ndvi_2" = as.numeric(coefs_clr %>% dplyr::filter(grepl("ndvi_sq", coefs)) %>% 
                          pull(value) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "canopy" = as.numeric(coefs_clr %>% dplyr::filter(grepl("canopy", coefs) & !grepl("sq", coefs)) %>% 
                          pull(value) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "canopy_2" = as.numeric(coefs_clr %>% dplyr::filter(grepl("canopy_sq", coefs)) %>% 
                            pull(value) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "wofs" = as.numeric(coefs_clr %>% dplyr::filter(grepl("wofs", coefs) & !grepl("sq", coefs)) %>% 
                          pull(value) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "slope" = as.numeric(coefs_clr %>% dplyr::filter(grepl("slope", coefs)) %>% 
                          pull(value) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "herby" = as.numeric(coefs_clr %>% dplyr::filter(grepl("herby", coefs)) %>% 
                         pull(value) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "memory" = as.numeric(coefs_clr %>% dplyr::filter(grepl("memory", coefs)) %>% 
                          pull(value) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "sl" = as.numeric(coefs_clr %>% dplyr::filter(grepl("step_l", coefs) & !grepl("sqrt", coefs)) %>% 
                      pull(value) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "sl_sqrt" = as.numeric(coefs_clr %>% dplyr::filter(grepl("step_sqrt", coefs)) %>% 
                      pull(value) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "cos_ta" = as.numeric(coefs_clr %>% dplyr::filter(grepl("cos", coefs)) %>% 
                          pull(value) %>% t() %*% t(as.matrix(hour_harmonics_df))))

harmonics_scaled_long <- pivot_longer(harmonics_scaled_df, cols = !1, names_to = "coef")

```

Temporally dynamic scaled external selection parameters

```{r}

ggplot() +
    geom_path(data = harmonics_scaled_long,
              aes(x = hour, y = value, colour = coef)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    scale_y_continuous(expression(Time-varying~parameter~values~beta)) +
    scale_x_continuous("Hour") +
    scale_color_viridis_d("Estimate") +
    ggtitle("All estimated parameters") +
    theme_classic() +
    theme(legend.position = "bottom")

ggplot() +
    geom_path(data = harmonics_scaled_long %>%
              filter(!coef %in% c("sl", "cos_ta", "memory")),
              aes(x = hour, y = value, colour = coef)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    scale_y_continuous(expression(Time-varying~parameter~values~beta)) +
    scale_x_continuous("Hour") +
    scale_color_viridis_d("Estimate") +
    ggtitle("External selection parameters") +
    theme_classic() +
    theme(legend.position = "bottom")

ggplot() +
    geom_path(data = harmonics_scaled_long %>%
              filter(!coef %in% c("ndvi", "ndvi_2", "canopy", "canopy_2", "sl", "cos_ta", "memory")),
              aes(x = hour, y = value, colour = coef)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    scale_y_continuous(expression(Time-varying~parameter~values~beta)) +
    scale_x_continuous("Hour") +
    scale_color_viridis_d("Estimate") +
    ggtitle("Non-quadratic external selection parameters") +
    theme_classic() +
    theme(legend.position = "bottom")

ggplot() +
    geom_path(data = harmonics_scaled_long %>%
              filter(coef %in% c("memory")), 
              aes(x = hour, y = value, colour = coef)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    scale_y_continuous(expression(Time-varying~parameter~values~beta)) +
    scale_x_continuous("Hour") +
    scale_color_viridis_d("Estimate") +
    ggtitle("Memory coefficent") +
    theme_classic() +
    theme(legend.position = "bottom")

# temporally dynamic scaled movement parameters
ggplot() +
    geom_path(data = harmonics_scaled_long %>%
              filter(coef %in% c("sl", "sl_sqrt", "cos_ta")),
              aes(x = hour, y = value, colour = coef)) +
    geom_hline(yintercept = 0, linetype = "dashed") +
    scale_y_continuous(expression(Time-varying~parameter~values~beta)) +
    scale_x_continuous("Hour") +
    scale_color_viridis_d("Estimate") +
    ggtitle("Scaled movement parameters") +
    theme_classic() +
    theme(legend.position = "bottom")

# ggsave(paste("outputs/plots/clr_fitting/clr_3harmonics_all_quads_20230519.png", sep = ""),
#   width=150, height=90, units="mm", dpi = 300)
# ggsave(paste("outputs/plots/clr_fitting/clr_harmonic_all_pres_20230208.png", sep = ""),
#   width=300, height=180, units="mm", dpi = 300)

```

For the natural scale parameters 

```{r}

harmonics_nat_df <- data.frame(
  "hour" = hour,
  "ndvi" = as.numeric(coefs_clr %>% dplyr::filter(grepl("ndvi", coefs) & !grepl("sq", coefs)) %>% 
                        pull(value_nat) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "ndvi_2" = as.numeric(coefs_clr %>% dplyr::filter(grepl("ndvi_sq", coefs)) %>% 
                          pull(value_nat) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "canopy" = as.numeric(coefs_clr %>% dplyr::filter(grepl("canopy", coefs) & !grepl("sq", coefs)) %>% 
                          pull(value_nat) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "canopy_2" = as.numeric(coefs_clr %>% dplyr::filter(grepl("canopy_sq", coefs)) %>% 
                            pull(value_nat) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "wofs" = as.numeric(coefs_clr %>% dplyr::filter(grepl("wofs", coefs) & !grepl("sq", coefs)) %>% 
                        pull(value_nat) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "slope" = as.numeric(coefs_clr %>% dplyr::filter(grepl("slope", coefs) & !grepl("sq", coefs)) %>% 
                        pull(value_nat) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "herby" = as.numeric(coefs_clr %>% dplyr::filter(grepl("herby", coefs)) %>% 
                         pull(value_nat) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "memory" = as.numeric(coefs_clr %>% dplyr::filter(grepl("memory", coefs)& !grepl("sq", coefs)) %>% 
                          pull(value_nat) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "sl" = as.numeric(coefs_clr %>% dplyr::filter(grepl("step_l", coefs) & !grepl("sqrt", coefs)) %>% 
                      pull(value_nat) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "sl_sqrt" = as.numeric(coefs_clr %>% dplyr::filter(grepl("step_sqrt", coefs)) %>% 
                      pull(value_nat) %>% t() %*% t(as.matrix(hour_harmonics_df))),
  "cos_ta" = as.numeric(coefs_clr %>% dplyr::filter(grepl("cos", coefs)) %>% 
                          pull(value_nat) %>% t() %*% t(as.matrix(hour_harmonics_df))))

```

Reconstructing the Gamma and von Mises distributions from the tentative distributions (from Fieberg et al 2021: Appendix C)

```{r}

# from the step gen script
tentative_rate <- 0.004271454
tentative_kappa <- 0.1848126

harmonics_nat_df$sl
harmonics_nat_df$sl - tentative_rate
harmonics_nat_df$sl_sqrt
# (harmonics_nat_df$sl - tentative_rate) - harmonics_nat_df$sl_sqrt

hour_coefs_nat_df <- harmonics_nat_df %>% mutate(kappa = tentative_kappa + cos_ta,
                                                 # rate = tentative_rate - sl
                                                 lambda_sl = sl - tentative_rate
                                                 # mean_sl = 1/rate,
                                                 # median_sl = log(2)/rate
                                                 )

# write_csv(hour_coefs_nat_df, paste0("outputs/clr_TS_daily2p_EvM_memory1000nat_coefs_dry_df_",Sys.Date(), ".csv"))

# turning into a long data frame
hour_coefs_nat_long <- pivot_longer(hour_coefs_nat_df, cols = !1, names_to = "coef")

```

Temporally dynamic natural-scale movement parameters

```{r}

ggplot() +
  geom_path(data = hour_coefs_nat_long %>% filter(coef == "rate"),
            aes(x = hour, y = value*100, colour = coef)) +
  geom_path(data = hour_coefs_nat_long %>% filter(coef == "sl_sqrt"),
            aes(x = hour, y = value, colour = coef)) +
  geom_path(data = hour_coefs_nat_long %>% filter(coef == "kappa"),
            aes(x = hour, y = value, colour = coef)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_y_continuous(expression(beta)) +
  scale_x_continuous("Hour", breaks = seq(0,24,2)) +
  scale_color_discrete("Estimate") +
  # ggtitle(coef_titles[i]) +
  theme_classic() +
  theme(legend.position = "bottom")

```

Comparing the observed and fitted step lengths through the hours of the day

```{r}

movement_summary_obs <- buffalo_data_all %>% filter(y == 1) %>%  group_by(id, hour) %>% summarise(mean_sl = mean(sl), median_sl = median(sl))

ggplot() +
  geom_path(data = movement_summary_obs, aes(x = hour, y = mean_sl, colour = factor(id))) +
  geom_path(data = hour_coefs_nat_df, aes(x = hour, y = mean_sl), colour = "red", linetype = "dashed") +
  scale_colour_viridis_d() +
  theme_classic()

ggplot() +
  geom_path(data = movement_summary_obs, aes(x = hour, y = median_sl, colour = factor(id))) +
  geom_path(data = hour_coefs_nat_df, aes(x = hour, y = median_sl), colour = "red", linetype = "dashed") +
  scale_colour_viridis_d() +
  theme_classic()

```

Creating step length pdf using sl and sqrt(sl) parameters

```{r}

# add in the rate parameter when estimated without the sqrt(sl) parameter
# prior to fitting with sqrt term
hourly_coefs <- read_csv("outputs/clr_TS_daily2p_EvM_memory1000nat_coefs_dry_df_2023-10-25.csv")

```

After fitting with sqrt term

```{r}

max_sl <- max(buffalo_data_all$sl_)
hist(buffalo_data_all$sl_, breaks = 1000)
quantile(buffalo_data_all$sl_, probs = c(0.01, 0.5, 0.9, 0.95, 0.99))

# max_x <- max_sl
max_x <- quantile(buffalo_data_all$sl_, probs = 0.99)[[1]]
x <- seq(1,max_x,1)

exp_sqrt_pdf <- function(x, lambda_sl, beta2) {
  exp((lambda_sl * x) + (beta2 * sqrt(x)))
}

# refactorisation - should be the same as above
# exp_sqrt_pdf <- function(x, lambda_sl, beta2) {
#   exp(x * (lambda_sl + (beta2 / sqrt(x))))
# }


for(i in 1:24) {
  
  # png(paste0("outputs/plots/sl_sqrt_sl_pdfs/pdf_q99_sl_", i, ".png"))
  # png(paste0("outputs/plots/sl_sqrt_sl_pdfs/pdf_max_sl_", i, ".png"))
  
  plot(exp_sqrt_pdf(x, lambda_sl = hour_coefs_nat_df$lambda_sl[i], beta2 = hour_coefs_nat_df$sl_sqrt[i]), 
       type = "l",
       xlab = "step length",
       ylab = "probability density",
       main = paste0("hour ", i))
  
  # plot(exp_sqrt_pdf(x, lambda_sl = hour_coefs_nat_df$lambda_sl[i], beta2 = hour_coefs_nat_df$sl_sqrt[i]) / sum(exp_sqrt_pdf(x, lambda_sl = hour_coefs_nat_df$lambda_sl[i], beta2 = hour_coefs_nat_df$sl_sqrt[i])), type = "l", main = paste0("hour ", i))
  
  # lines(dexp(x, rate = hourly_coefs$rate[i]), col = "red")
  
  # dev.off()
  
}

```

To estimate an exponential distribution for accept-reject sampling

```{r}

for(i in 1:24) {

# exp_rate_greater <- hour_coefs_nat_df$lambda_sl[i] + (hour_coefs_nat_df$sl_sqrt[i] / sqrt(max_x))
# print(exp_rate_greater)

exp_sqrt_pdf(max_x, lambda_sl = hour_coefs_nat_df$lambda_sl[i], beta2 = hour_coefs_nat_df$sl_sqrt[i])
# exp_rate_greater * exp(max_x * exp_rate_greater)

dexp(max_x, rate = 0.0002175034)

# 0.0003234013 maximum value that can be taken by the exponential distribution at x = 1137
# at rate of 0.0009

  fx_1 <- (exp_sqrt_pdf(0, lambda_sl = hour_coefs_nat_df$lambda_sl[i], beta2 = hour_coefs_nat_df$sl_sqrt[i]))

  hx_1 <- dexp(0, rate = 0.0002175034)

  cx_1 <- (fx_1 / hx_1)
  print(paste0("Scaling factor is ", cx_1))

  plot(exp_sqrt_pdf(x, lambda_sl = hour_coefs_nat_df$lambda_sl[i], beta2 = hour_coefs_nat_df$sl_sqrt[i]), 
       type = "l", main = paste0("hour ", i))
  
  lines(dexp(x, rate = hourly_coefs$rate[i]), col = "blue")
  lines(cx_1 * dexp(x, rate = 0.0002175034), col = "red")

  fx_max_x <- (exp_sqrt_pdf(x, lambda_sl = hour_coefs_nat_df$lambda_sl[i], beta2 = hour_coefs_nat_df$sl_sqrt[i]) / sum(exp_sqrt_pdf(x, lambda_sl = hour_coefs_nat_df$lambda_sl[i], beta2 = hour_coefs_nat_df$sl_sqrt[i])))[max_x]

  hx_max_x <- dexp(x, rate = -exp_rate_greater)[max_x]

  support_max_x <- hx_max_x / fx_max_x
  print(paste0("Ratio between proposal and target at max_x is ", support_max_x))
  
}

```

```{r}

# Function to calculate the PDF of exponential distribution for a given x and lambda
exp_pdf <- function(lambda, x) {
  lambda * exp(-lambda * x)
}

optimise(exp_pdf, interval = c(0.0001, 0.01), maximum = FALSE, x = max_x)

# Define the x value
x_value <- max_x

# Define a range of lambda values
lambda_values <- seq(0.00001, 0.01, by = 0.0001) # Adjust the range and step as needed

# Calculate PDF values for each lambda
pdf_values <- sapply(lambda_values, function(lambda) exp_pdf(lambda, x_value))

# Create a data frame to store lambda and corresponding PDF values
result_df <- data.frame(lambda = lambda_values, pdf = pdf_values)

# Print the first few rows of the result
head(result_df)
result_df$lambda[which.max(result_df$pdf)]
max(pdf_values)

# Plot the PDF values against lambda
plot(result_df$lambda, result_df$pdf, type = "l", xlab = "lambda", ylab = "PDF")

```

Optimising to find a lamdba value that results in a probability density equal to that of the exp_sprt_df function

```{r}

# Define your exp_sqrt_pdf function
exp_sqrt_pdf <- function(x, lambda_sl, beta2) {
  exp((lambda_sl * x) + (beta2 * sqrt(x)))
}

# Function to find the difference between the two densities
density_difference <- function(lambda, x, lambda_sl, beta2) {
  exp_density <- lambda * exp(-lambda * x)
  target_density <- exp_sqrt_pdf(x, lambda_sl, beta2)
  return(exp_density - target_density)
}

density_difference(0.00001, x = max_x, lambda_sl = hour_coefs_nat_df$lambda_sl[1], beta2 = hour_coefs_nat_df$sl_sqrt[1])

i = 1
# Example parameters
lambda_sl <- hour_coefs_nat_df$lambda_sl[i]
beta2 <- hour_coefs_nat_df$sl_sqrt[i]
x_value <- max_x  # Example x value where you want the densities to match

# Numerical solution
solution <- uniroot(density_difference, 
                    lower = 0.0001, upper = 0.001, 
                    x = x_value, lambda_sl = lambda_sl, beta2 = beta2)

lambda_solution <- solution$root

```



### Creating two dimensional selection plots

Contour plot for NDVI

```{r}

ndvi_min <- min(buffalo_data$ndvi_temporal, na.rm = TRUE)
ndvi_max <- max(buffalo_data$ndvi_temporal, na.rm = TRUE)
ndvi_seq <- seq(ndvi_min, ndvi_max, by = 0.01)

# Create empty data frame
ndvi_fresponse_df <- data.frame(matrix(ncol = nrow(hour_coefs_nat_df), nrow = length(ndvi_seq)))
for(i in 1:nrow(hour_coefs_nat_df)) {
  # Assign the vector as a column to the dataframe
  ndvi_fresponse_df[,i] <- (hour_coefs_nat_df$ndvi[i] * ndvi_seq) + (hour_coefs_nat_df$ndvi_2[i] * (ndvi_seq ^ 2))
}

ndvi_fresponse_df <- data.frame(ndvi_seq, ndvi_fresponse_df)
colnames(ndvi_fresponse_df) <- c("ndvi", hour)
ndvi_fresponse_long <- pivot_longer(ndvi_fresponse_df, cols = !1, names_to = "hour")

ndvi_contour_max <- max(ndvi_fresponse_long$value) # 0.7890195
ndvi_contour_min <- min(ndvi_fresponse_long$value) # -0.7945691
ndvi_contour_increment <- (ndvi_contour_max-ndvi_contour_min)/10

ggplot(data = ndvi_fresponse_long, aes(x = as.numeric(hour), y = ndvi)) +
  geom_point(aes(colour = value)) + # colour = "white"
  geom_contour(aes(z = value), 
               breaks = seq(ndvi_contour_increment, ndvi_contour_max, ndvi_contour_increment), 
               colour = "black", linewidth = 0.25, linetype = "dashed") +
  geom_contour(aes(z = value), 
               breaks = seq(-ndvi_contour_increment, ndvi_contour_min, -ndvi_contour_increment), 
               colour = "red", linewidth = 0.25, linetype = "dashed") +
  geom_contour(aes(z = value), breaks = 0, colour = "black", linewidth = 0.5) +
  scale_x_continuous("Hour", breaks = seq(0,24,6)) +
  scale_y_continuous("NDVI value", breaks = seq(-1, 1, 0.25)) +
  scale_colour_viridis_c("Selection") +
  ggtitle("Normalised Difference Vegetation Index (NDVI)") +
  theme_classic()

# for manuscript
ggsave(paste0("outputs/plots/clr_fitting/CLR_TS_2pdaily_EvM_memory1000nat_dry_ndvi_quad_", Sys.Date(), ".png"),
  width=150, height=90, units="mm", dpi = 300)

```

Canopy cover

```{r}

canopy_min <- min(buffalo_data$canopy_01)
canopy_max <- max(buffalo_data$canopy_01)
canopy_seq <- seq(canopy_min, canopy_max, by = 0.01)

# Create empty data frame
canopy_fresponse_df <- data.frame(matrix(ncol = nrow(hour_coefs_nat_df), nrow = length(canopy_seq)))
for(i in 1:nrow(hour_coefs_nat_df)) {
  # Assign the vector as a column to the dataframe
  canopy_fresponse_df[,i] <- (hour_coefs_nat_df$canopy[i] * canopy_seq) + (hour_coefs_nat_df$canopy_2[i] * (canopy_seq ^ 2))
}

canopy_fresponse_df <- data.frame(canopy_seq, canopy_fresponse_df)
colnames(canopy_fresponse_df) <- c("canopy", hour)
canopy_fresponse_long <- pivot_longer(canopy_fresponse_df, cols = !1, names_to = "hour")

canopy_contour_min <- min(canopy_fresponse_long$value) # 0
canopy_contour_max <- max(canopy_fresponse_long$value) # 2.181749
canopy_contour_increment <- (canopy_contour_max-canopy_contour_min)/10

ggplot(data = canopy_fresponse_long, aes(x = as.numeric(hour), y = canopy)) +
  geom_point(aes(colour = value)) +
  geom_contour(aes(z = value), 
               breaks = seq(canopy_contour_increment, canopy_contour_max, canopy_contour_increment), 
               colour = "black", linewidth = 0.25, linetype = "dashed") +
  geom_contour(aes(z = value),
               breaks = seq(-canopy_contour_increment, canopy_contour_min, -canopy_contour_increment),
               colour = "red", linewidth = 0.25, linetype = "dashed") +
  geom_contour(aes(z = value), breaks = 0, colour = "black", linewidth = 0.25) +
  scale_x_continuous("Hour", breaks = seq(0,24,6)) +
  scale_y_continuous("Canopy cover (proportion)", breaks = seq(0, 1, 0.25)) +
  scale_colour_viridis_c("Selection") +
  ggtitle("Canopy Cover") +
  theme_classic()

# for manuscript
ggsave(paste0("outputs/plots/clr_fitting/CLR_TS_2pdaily_EvM_memory1000nat_dry_canopy_quad_", Sys.Date(), ".png"),
  width=150, height=90, units="mm", dpi = 300)

```

Constructing distributions of the parameter estimates for uncertainty quantification

```{r}

n_estims <- 1e3

# uncorrelated marginal distributions
hist(rnorm(n = n_estims, mean = model_twostep_2p_harms$beta[1], sd = model_twostep_2p_harms$se[1]), 
     main = "Distribution of linear NDVI coefficient", 
     xlab = "Coefficent value",
     breaks = 100)
abline(v = model_twostep_2p_harms$beta[1], col = "red")

# using the correlation matrix
r_estims_corr <- MASS::mvrnorm(n = n_estims, mu = model_twostep_2p_harms$beta, Sigma = model_twostep_2p_harms$vcov)
min(r_estims_corr)
max(r_estims_corr)

# for(i in 1:ncol(r_estims_corr)) { 
#   hist(r_estims_corr[,i], xlim = c(-3,2), main = colnames(r_estims_corr)[i])
#   abline(v = model_twostep_2p_harms$beta[i])
# }

param_uncertainty_estims <- data.frame(rbind(model_twostep_2p_harms$beta, r_estims_corr))
rownames(param_uncertainty_estims) <- c("mean", paste0("r", 1:n_estims))

param_uncertainty_estims_nat <- matrix(data = NA, nrow = n_estims+1, ncol = ncol(param_uncertainty_estims))
for(i in 1:ncol(param_uncertainty_estims)) {
param_uncertainty_estims_nat[,i] <- param_uncertainty_estims[,i] / scaling_attributes$sd[i] 
}

rownames(param_uncertainty_estims_nat) <- rownames(param_uncertainty_estims)
colnames(param_uncertainty_estims_nat) <- colnames(param_uncertainty_estims)
param_uncertainty_estims_nat <- data.frame(param_uncertainty_estims_nat)

```

Reconstructing coefficients with two pairs of harmonics, with quadratic terms

```{r}

hour <- seq(0,23.9,0.1)
# hour <- seq(1,24,1)

hour_harmonics_df <- data.frame("linear_term" = rep(1, length(hour)),
                                "hour_s1" = sin(2*pi*hour/24),
                                "hour_s2" = sin(4*pi*hour/24),
                                "hour_c1" = cos(2*pi*hour/24),
                                "hour_c2" = cos(4*pi*hour/24))

harmonics_scaled_df_list <- vector(mode = "list", length = length(buffalo_ids))
harmonics_scaled_long_list <- vector(mode = "list", length = length(buffalo_ids))

for(i in 1:(nrow(param_uncertainty_estims))) {

  harmonics_scaled_df_list[[i]] <- data.frame(
    
    "id" = rownames(param_uncertainty_estims)[i],
    "hour" = hour,
    "ndvi" = as.numeric(param_uncertainty_estims %>% dplyr::select(matches("ndvi") & !matches("sq")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "ndvi_2" = as.numeric(param_uncertainty_estims %>% dplyr::select(matches("ndvi_sq")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "canopy" = as.numeric(param_uncertainty_estims %>% dplyr::select(matches("canopy") & !matches("sq")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "canopy_2" = as.numeric(param_uncertainty_estims %>% dplyr::select(matches("canopy_sq")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "wofs" = as.numeric(param_uncertainty_estims %>% dplyr::select(matches("wofs")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "slope" = as.numeric(param_uncertainty_estims %>% dplyr::select(matches("slope")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "herby" = as.numeric(param_uncertainty_estims %>% dplyr::select(matches("herby")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "memory" = as.numeric(param_uncertainty_estims %>% dplyr::select(matches("memory")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "sl" = as.numeric(param_uncertainty_estims %>% dplyr::select(matches("step_l") & !matches("log")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "cos_ta" = as.numeric(param_uncertainty_estims %>% dplyr::select(matches("cos")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))))
  
  harmonics_scaled_long_list[[i]] <- pivot_longer(harmonics_scaled_df_list[[i]], cols = !1:2, names_to = "coef")

}

harmonics_scaled_long_all <- bind_rows(harmonics_scaled_long_list)
# harmonics_scaled_long_all$id <- rep(names(param_uncertainty_estims)[2:1002], each = 11*length(hour))

```


```{r}

ggplot() +
  geom_path(data = harmonics_scaled_long_all %>% filter(coef %in% c("wofs", "slope", "herby")),
            aes(x = hour, y = value, colour = coef, group = interaction(coef, id)), alpha = 0.05) +
  geom_path(data = harmonics_scaled_long_all %>% filter(coef %in% c("wofs", "slope", "herby") & id == "mean"),
            aes(x = hour, y = value, colour = coef, group = interaction(coef, id)), colour = "black") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_y_continuous(expression(Time-varying~parameter~values~beta)) +
  scale_x_continuous("Hour", breaks = seq(0,24,6)) +
  # scale_color_discrete("Estimate") +
  scale_color_viridis_d("Estimate") +
  # ggtitle() +
  theme_classic()# +
  theme(legend.position = "none")

# for manuscript
ggsave(paste0("outputs/plots/clr_fitting/CLR_TS_2pDailyMem1000_EvM_wofs_slope_herby_", Sys.Date(), ".png"),
  width=150, height=90, units="mm", dpi = 300)

ggplot() +
    geom_path(data = harmonics_scaled_long_all %>% filter(coef == "memory"),
              aes(x = hour, y = value, group = id), 
              colour = "black", alpha = 0.05) +
  geom_path(data = harmonics_scaled_long_all %>% filter(coef == "memory" & id == "mean"),
              aes(x = hour, y = value), colour = "red") +
    geom_hline(yintercept = 0, linetype = "dashed") +
    scale_y_continuous(expression(Time-varying~parameter~values~beta)) +
  scale_x_continuous("Hour", breaks = seq(0,24,6)) +
    # scale_color_discrete("Estimate") +
    scale_color_viridis_d("Estimate") +
    ggtitle("Spatiotemporal Memory") +
    theme_classic() +
    theme(legend.position = "none")

# for manuscript
ggsave(paste0("outputs/plots/clr_fitting/CLR_TS_2pDailyMem1000_EvM_memory_", Sys.Date(), ".png"),
  width=150, height=90, units="mm", dpi = 300)

```

For the natural scale parameters 

```{r}

harmonics_nat_df_list <- vector(mode = "list", length = length(buffalo_ids))

for(i in 1:(nrow(param_uncertainty_estims_nat))) {

  harmonics_nat_df_list[[i]] <- data.frame(
    
    "id" = rownames(param_uncertainty_estims_nat)[i],
    "hour" = hour,
    "ndvi" = as.numeric(param_uncertainty_estims_nat %>% dplyr::select(matches("ndvi") & !matches("sq")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "ndvi_2" = as.numeric(param_uncertainty_estims_nat %>% dplyr::select(matches("ndvi_sq")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "canopy" = as.numeric(param_uncertainty_estims_nat %>% dplyr::select(matches("canopy") & !matches("sq")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "canopy_2" = as.numeric(param_uncertainty_estims_nat %>% dplyr::select(matches("canopy_sq")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "wofs" = as.numeric(param_uncertainty_estims_nat %>% dplyr::select(matches("wofs")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "slope" = as.numeric(param_uncertainty_estims_nat %>% dplyr::select(matches("slope")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "herby" = as.numeric(param_uncertainty_estims_nat %>% dplyr::select(matches("herby")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "memory" = as.numeric(param_uncertainty_estims_nat %>% dplyr::select(matches("memory")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "sl" = as.numeric(param_uncertainty_estims_nat %>% dplyr::select(matches("step_l") & !matches("log")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))),
    "cos_ta" = as.numeric(param_uncertainty_estims_nat %>% dplyr::select(matches("cos")) %>% 
                        slice(i) %>% as.numeric() %*% t(as.matrix(hour_harmonics_df))))

}

```

Reconstructing the Gamma and von Mises distributions from the tentative distributions (from Fieberg et al 2021: Appendix C)

```{r}

# from the step gen script
tentative_rate <- 0.004271454
tentative_kappa <- 0.1848126

hour_coefs_nat_df_list <- vector(mode = "list", length = length(buffalo_ids))
# harmonics_nat_long_list <- vector(mode = "list", length = length(buffalo_ids))

for(i in 1:length(harmonics_nat_df_list)) {
  
  hour_coefs_nat_df_list[[i]] <- harmonics_nat_df_list[[i]] %>% mutate(rate = tentative_rate - sl,
                                                                       kappa = tentative_kappa + cos_ta,
                                                                       mean_sl = 1/rate,
                                                                       median_sl = log(2)/rate)

  # turning into a long data frame
  # harmonics_nat_long_list[[i]] <- pivot_longer(hour_coefs_nat_df_list[[i]], cols = !1:2, names_to = "coef")

}

harmonics_nat_df_all <- bind_rows(hour_coefs_nat_df_list)
harmonics_nat_df_long <- pivot_longer(harmonics_nat_df_all, cols = !1:2, names_to = "coef")

write_csv(harmonics_nat_df_all, paste0("outputs/clr_TS_uncertainty_daily2p_EvM_memory1000_coefs_dry_df",Sys.Date(), ".csv"))

```



```{r}

ggplot() +
  geom_path(data = harmonics_nat_df_long %>% filter(coef == "rate"),
            aes(x = hour, y = value*100, colour = coef, group = interaction(coef, id)), alpha = 0.05) +
  geom_path(data = harmonics_nat_df_long %>% filter(coef == "rate" & id == "mean"),
            aes(x = hour, y = value*100), colour = "black") +
  geom_path(data = harmonics_nat_df_long %>% filter(coef == "kappa"),
            aes(x = hour, y = value, colour = coef, group = id), alpha = 0.1) +
  geom_path(data = harmonics_nat_df_long %>% filter(coef %in% c("rate", "kappa") & id == "mean"),
            aes(x = hour, y = value, colour = coef, group = interaction(coef, id)), colour = "black") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  scale_y_continuous(expression(beta)) +
  scale_x_continuous("Hour", breaks = seq(0,24,2)) +
  scale_color_viridis_d("Estimate") +
  theme_classic() +
  theme(legend.position = "bottom")

```

