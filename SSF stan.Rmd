---
title: "SSF stan"
author: "Scott Forrest"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# update.packages(ask = FALSE, checkBuilt = TRUE)

```



```{r}
#message = FALSE

# devtools::install_github("jmsigner/amt")
# install.packages("amt")

library(tidyverse)

library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())

# install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
# remotes::install_github("stan-dev/cmdstanr")
# library(cmdstanr)
# install_cmdstan(dir = "C:/Users/n11207361", cores = 2, overwrite = TRUE)

# set_cmdstan_path("C:/cmdstan")
# cmdstan_path()

packages <- c("amt", "lubridate", "mgcv", "survival", "terra", "raster", "tictoc", "RColorBrewer", "patchwork", "ecospat", "ggmap", "basemaps", "mapedit", "sf", "brms", "beepr", "shinystan")
walk(packages, require, character.only = T)

```


## Use data prep markdown document to import and prepare buffalo telemetry data

Creating stan-specific covariates (i.e. something like a design matrix)

```{r}

buffalo_CLR_year_harmonics <- buffalo_CLR_year %>% mutate(
  
                            ndvi_s1 = ndvi_scaled[,1] * yday_s1,
                            ndvi_s2 = ndvi_scaled[,1] * yday_s2,
                            ndvi_s3 = ndvi_scaled[,1] * yday_s3,
                            ndvi_s4 = ndvi_scaled[,1] * yday_s4,
                            ndvi_c1 = ndvi_scaled[,1] * yday_c1,
                            ndvi_c2 = ndvi_scaled[,1] * yday_c2,
                            ndvi_c3 = ndvi_scaled[,1] * yday_c3,
                            ndvi_c4 = ndvi_scaled[,1] * yday_c4,
                            
                            ndvi_2 = ndvi_scaled[,1]^2,
                            ndvi_2_s1 = ndvi_2 * yday_s1,
                            ndvi_2_s2 = ndvi_2 * yday_s2,
                            ndvi_2_s3 = ndvi_2 * yday_s3,
                            ndvi_2_s4 = ndvi_2 * yday_s4,
                            ndvi_2_c1 = ndvi_2 * yday_c1,
                            ndvi_2_c2 = ndvi_2 * yday_c2,
                            ndvi_2_c3 = ndvi_2 * yday_c3,
                            ndvi_2_c4 = ndvi_2 * yday_c4,
                            
                            canopy_s1 = canopy_scaled[,1] * yday_s1,
                            canopy_s2 = canopy_scaled[,1] * yday_s2,
                            canopy_s3 = canopy_scaled[,1] * yday_s3,
                            canopy_s4 = canopy_scaled[,1] * yday_s4,
                            canopy_c1 = canopy_scaled[,1] * yday_c1,
                            canopy_c2 = canopy_scaled[,1] * yday_c2,
                            canopy_c3 = canopy_scaled[,1] * yday_c3,
                            canopy_c4 = canopy_scaled[,1] * yday_c4,
                            
                            canopy_2 = canopy_scaled[,1]^2,
                            canopy_2_s1 = canopy_2 * yday_s1,
                            canopy_2_s2 = canopy_2 * yday_s2,
                            canopy_2_s3 = canopy_2 * yday_s3,
                            canopy_2_s4 = canopy_2 * yday_s4,
                            canopy_2_c1 = canopy_2 * yday_c1,
                            canopy_2_c2 = canopy_2 * yday_c2,
                            canopy_2_c3 = canopy_2 * yday_c3,
                            canopy_2_c4 = canopy_2 * yday_c4,
                            
                            sl_s1 = sl * yday_s1,
                            sl_s2 = sl * yday_s2,
                            sl_s3 = sl * yday_s3,
                            sl_s4 = sl * yday_s4,
                            sl_c1 = sl * yday_c1,
                            sl_c2 = sl * yday_c2,
                            sl_c3 = sl * yday_c3,
                            sl_c4 = sl * yday_c4,
                            
                            sl_scaled_s1 = sl_scaled * yday_s1,
                            sl_scaled_s2 = sl_scaled * yday_s2,
                            sl_scaled_s3 = sl_scaled * yday_s3,
                            sl_scaled_s4 = sl_scaled * yday_s4,
                            sl_scaled_c1 = sl_scaled * yday_c1,
                            sl_scaled_c2 = sl_scaled * yday_c2,
                            sl_scaled_c3 = sl_scaled * yday_c3,
                            sl_scaled_c4 = sl_scaled * yday_c4,
                            
                            log_sl_s1 = log_sl * yday_s1,
                            log_sl_s2 = log_sl * yday_s2,
                            log_sl_s3 = log_sl * yday_s3,
                            log_sl_s4 = log_sl * yday_s4,
                            log_sl_c1 = log_sl * yday_c1,
                            log_sl_c2 = log_sl * yday_c2,
                            log_sl_c3 = log_sl * yday_c3,
                            log_sl_c4 = log_sl * yday_c4,
                            
                            cos_ta_s1 = cos_ta * yday_s1,
                            cos_ta_s2 = cos_ta * yday_s2,
                            cos_ta_s3 = cos_ta * yday_s3,
                            cos_ta_s4 = cos_ta * yday_s4,
                            cos_ta_c1 = cos_ta * yday_c1,
                            cos_ta_c2 = cos_ta * yday_c2,
                            cos_ta_c3 = cos_ta * yday_c3,
                            cos_ta_c4 = cos_ta * yday_c4
                            
                            )

# plot(buffalo_CLR_year$yday, buffalo_CLR_year$ndvi_s1)
# plot(buffalo_CLR_year$yday, buffalo_CLR_year$ndvi_s2)

```


Checking distributions of covariates

```{r}

hist(buffalo_CLR_year$ndvi_scaled) # this one should better in the regression, then apply this scaling to the rasters for prediction
attributes(buffalo_CLR_year$ndvi_scaled)
# ndvi center = 0.3125089
# ndvi scale = 0.143179

hist(buffalo_CLR_year$ndvi_scaled_raster)
hist(buffalo_CLR_year$water_dist)
hist(buffalo_CLR_year$water_dist_log)
hist(buffalo_CLR_year$herby_scaled)
hist(buffalo_CLR_year$canopy_scaled)
hist(buffalo_CLR_year$DEM_H_end, breaks = 100)
hist(buffalo_CLR_year$elev_scaled, breaks = 100)
hist(buffalo_CLR_year$elev_log, breaks = 100)
# hist(buffalo_CLR_year$elev_log_scaled, breaks = 100)
hist(buffalo_CLR_year$elev_delta, breaks = 100)
hist(buffalo_CLR_year$elev_delta_scaled, breaks = 100)

```


Checking the harmonic transformations - use day of the year rather than the month

```{r}

ggplot() +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = month, y = month_s1), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = month, y = month_s2), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = month, y = month_s3), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = month, y = month_s4), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = month, y = month_c1), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = month, y = month_c2), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = month, y = month_c3), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = month, y = month_c4), size = 0.1) +
  theme_classic()

ggplot() +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = yday, y = yday_s1), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = yday, y = yday_s2), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = yday, y = yday_s3), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = yday, y = yday_s4), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = yday, y = yday_c1), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = yday, y = yday_c2), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = yday, y = yday_c3), size = 0.1) +
  geom_line(data = buffalo_CLR_year %>% filter(id == 2005), aes(x = yday, y = yday_c4), size = 0.1) +
  theme_classic()

```

Thinning the pseudo-absences

```{r}

buffalo_CLR_year_harmonics %>% dplyr::group_by(id, step_id) %>% dplyr::summarise(n=n())
buffalo_CLR_year_3pts <- buffalo_CLR_year_harmonics %>% dplyr::group_by(id, step_id) %>% dplyr::slice_head(n = 4) %>%  # only keep 3 random points per used point
  dplyr::ungroup()

head(buffalo_CLR_year_3pts)

```


Create a subset of the data to use in the stan model

```{r}

# buffalo_subset <- buffalo_all_covs %>% 
#   filter(year == 2018 & (month == 11 | month == 12) & (id == 2005 | id == 2018)) %>% 
#   drop_na(ndvi_temporal, ndwi_temporal) %>% 
#   mutate(id_num = as.numeric(factor(id)), step_id = step_id_, log_sl = log_sl_, cos_ta = cos_ta_) %>% 
#   dplyr::select(id, id_num, ndvi_temporal, ndwi_temporal, y, step_id)

# choose one for subsetting
# buffalo_CLR_year_3pts
# buffalo_CLR_year_harmonics

# buffalo_subset <- buffalo_CLR_year_harmonics %>%
buffalo_subset <- buffalo_CLR_year_3pts %>%
  # filter(year == 2019 & month == 11) %>% 
  # filter(id == 2005 | id == 2014)  %>%
  mutate(id_num = as.numeric(factor(id))) %>% 
  dplyr::select(id, 
                id_num, 
                
                ndvi_scaled, 
                ndvi_s1,
                ndvi_s2,
                ndvi_s3,
                ndvi_s4,
                ndvi_c1,
                ndvi_c2,
                ndvi_c3,
                ndvi_c4,
                
                ndvi_2, 
                ndvi_2_s1,
                ndvi_2_s2,
                ndvi_2_s3,
                ndvi_2_s4,
                ndvi_2_c1,
                ndvi_2_c2,
                ndvi_2_c3,
                ndvi_2_c4,
                
                # herby_scaled, 
                
                canopy_scaled,
                canopy_s1,
                canopy_s2,
                canopy_s3,
                canopy_s4,
                canopy_c1,
                canopy_c2,
                canopy_c3,
                canopy_c4,
                
                canopy_2, 
                canopy_2_s1,
                canopy_2_s2,
                canopy_2_s3,
                canopy_2_s4,
                canopy_2_c1,
                canopy_2_c2,
                canopy_2_c3,
                canopy_2_c4,
                
                y, 
                step_id, 
                step_aligned,
                
                sl, 
                sl_s1,
                sl_s2,
                sl_s3,
                sl_s4,
                sl_c1,
                sl_c2,
                sl_c3,
                sl_c4,
                
                sl_scaled, 
                sl_scaled_s1,
                sl_scaled_s2,
                sl_scaled_s3,
                sl_scaled_s4,
                sl_scaled_c1,
                sl_scaled_c2,
                sl_scaled_c3,
                sl_scaled_c4,
                
                log_sl, 
                log_sl_s1,
                log_sl_s2,
                log_sl_s3,
                log_sl_s4,
                log_sl_c1,
                log_sl_c2,
                log_sl_c3,
                log_sl_c4,
                
                cos_ta,
                cos_ta_s1,
                cos_ta_s2,
                cos_ta_s3,
                cos_ta_s4,
                cos_ta_c1,
                cos_ta_c2,
                cos_ta_c3,
                cos_ta_c4) %>% 
  
  drop_na(cos_ta)

sum(is.na(buffalo_subset$cos_ta))

unique(buffalo_subset$id)
unique(buffalo_subset$id_num)

# ggplot() +
#   geom_point(data = buffalo_subset, aes(x = step_id, y = factor(id_num))) +
#   theme_classic()
# 
# ggplot() +
#   geom_point(data = buffalo_subset, aes(x = step_aligned, y = factor(id_num))) +
#   theme_classic()

```

Stan model without harmonic terms

```{r}

model <- "data {
  
  int<lower=1> N; // no data points
  int<lower=1> I; // no steps (over all individuals)
  int<lower=1> J; // no individuals
  
  int<lower=0> y[N]; // response
  real ndvi[N]; // covariate
  //real herby[N]; // covariate
  real canopy[N]; // covariate
  real sl[N]; // movement covariate
  real log_sl[N]; // movement covariate
  real cos_ta[N]; // movement covariate
  
  int<lower=1, upper=I> stepid[N]; // step id
  int<lower=1, upper=J> indid[N]; // individual id
  
}

parameters {
  vector[5] beta; // fixed effects
  vector[I] a_re; // RE for steps
  vector[J] i_re_ndvi; // RE effects for each individual - NDVI
  //vector[J] i_re_herby; // RE effects for each individual - Herbaceous vegetation
  vector[J] i_re_canopy; // RE effects for each individual - Canopy cover
  vector[J] i_re_sl; // RE effects for each individual - Step length
  vector[J] i_re_log_sl; // RE effects for each individual - Log of step length
  vector[J] i_re_cos_ta; // RE effects for each individual - Cos of turning angle
  
  real<lower = 0.0> sigmaind;
}


model {

  real mu;
  
  // priors
  // maybe add a prior for sd here
  //sigmaind ~ inv_gamma(0.01, 0.01);  
  // unpopular - half-normal / T instead (lower = 0) - try tight parameters

  sigmaind ~ normal(0.0, 1.0); 
  beta ~ normal(0.0, sigmaind);
  a_re ~ normal(0.0, 1000000.0);
  i_re_ndvi ~ normal(0.0, sigmaind);
  //i_re_herby ~ normal(0.0, sigmaind);
  i_re_canopy ~ normal(0.0, sigmaind);
  i_re_sl ~ normal(0.0, sigmaind);
  i_re_log_sl ~ normal(0.0, sigmaind);
  i_re_cos_ta ~ normal(0.0, sigmaind);
  

  //likelihood


  for (i in 1:N) {

    mu =  a_re[stepid[i]] + 
    (beta[1] + i_re_ndvi[indid[i]]) * ndvi[i] + 
    //(beta[2] + i_re_herby[indid[i]]) * herby[i] +
    (beta[2] + i_re_canopy[indid[i]]) * canopy[i] +
    (beta[3] + i_re_sl[indid[i]]) * sl[i] +
    (beta[4] + i_re_log_sl[indid[i]]) * log_sl[i] +
    (beta[5] + i_re_cos_ta[indid[i]]) * cos_ta[i];

    y[i] ~ poisson_log(mu);

  }

}
"

```


Prior predictive

```{r}

prior_pred <- "data {

  int<lower = 0> N;
  vector[N] x;
  
  int<lower=1> N; // no data points
  int<lower=1> I; // no steps (over all individuals)
  int<lower=1> J; // no individuals
  
  int<lower=0> y[N]; // response
  real ndvi[N]; // covariate
  real herby[N]; // covariate
  real canopy[N]; // covariate
  real sl[N]; // movement covariate
  real log_sl[N]; // movement covariate
  real cos_ta[N]; // movement covariate
  int<lower=1, upper=I> stepid[N]; // step id
  int<lower=1, upper=J> indid[N]; // individual id
  
}

generated quantities {

  real alpha = normal_rng(0, 1);
  real beta = normal_rng(0, 1);
  real y_sim[N] = poisson_log_rng(alpha + beta * x);
  
  
  
}
"

```


Compiling the model

```{r}

# compile the model
tic()
stan_mod <- stan_model(model_code = model)
toc()

# stancode <- 'data {real y_mean;} parameters {real y;} model {y ~ normal(y_mean,1);}'
# mod <- stan_model(model_code = stancode, verbose = TRUE)

# beep(sound = 2)

```

Preparing data for stan

```{r}

stan_dat <- list(N = nrow(buffalo_subset), 
                 I = length(unique(buffalo_subset$step_id)), 
                 J = length(unique(buffalo_subset$id_num)), 
                 y = buffalo_subset$y, 
                 ndvi = buffalo_subset$ndvi_scaled[,1], 
                 #herby = buffalo_subset$herby_scaled[,1],
                 canopy = buffalo_subset$canopy_scaled[,1],
                 sl = buffalo_subset$sl,
                 log_sl = buffalo_subset$log_sl,
                 cos_ta = buffalo_subset$cos_ta,
                 stepid = as.numeric(factor(buffalo_subset$step_id)), 
                 indid = buffalo_subset$id_num)

```


Fitting the model

```{r}

tic()
res_stan_mvmt <- optimizing(stan_mod, stan_dat, init = "0")
toc()

tic()
res_stan_mvmt <- sampling(stan_mod, stan_dat, init = "0", cores = 4, chains = 2, iter = 1000)
toc()

tic()
res_stan_mvmt_vb <- vb(stan_mod, stan_dat, init = "0")
toc()

# system("killall R")
# interrupt(res_stan_mvmt)

beep(sound = 2)

```

Checking summaries and sampling diagnostics

```{r}

res_stan_mvmt

summary(res_stan_mvmt)$summary[1:10, ]
tail(summary(res_stan_mvmt)$summary)
traceplot(res_stan_mvmt,pars=c("beta[1]", "beta[2]", "beta[3]", "a_re[1]", "a_re[2]"))

# print(res_stan)
plot(res_stan_mvmt, pars = "beta")
plot(res_stan_mvmt, pars = "beta", plotfun = "stan_hist")
extract(res_stan_mvmt, pars = "beta")

```


Stan model with harmonics 

```{r}

model <- "data {
  
  int<lower=1> N; // no data points
  int<lower=1> I; // no steps (over all individuals)
  int<lower=1> J; // no individuals
  
  int<lower=0> y[N]; // response
  
  real ndvi[N]; // covariate
  real ndvi_s1[N];
  real ndvi_s2[N];
  real ndvi_c1[N];
  real ndvi_c2[N]; 
    
  real canopy[N]; // covariate
  real canopy_s1[N];
  real canopy_s2[N];
  real canopy_c1[N];
  real canopy_c2[N]; 
  
  real sl[N]; // movement covariate
  real sl_s1[N];
  real sl_s2[N];
  real sl_c1[N];
  real sl_c2[N]; 
  
  real log_sl[N]; // movement covariate
  real log_sl_s1[N];
  real log_sl_s2[N];
  real log_sl_c1[N];
  real log_sl_c2[N]; 
  
  real cos_ta[N]; // movement covariate
  real cos_ta_s1[N];
  real cos_ta_s2[N];
  real cos_ta_c1[N];
  real cos_ta_c2[N]; 
  
  int<lower=1, upper=I> stepid[N]; // step id
  int<lower=1, upper=J> indid[N]; // individual id
  
}

parameters {

  vector[25] beta; // fixed effects
  vector[I] a_re; // RE for steps
  
  vector[J] i_re_ndvi; // RE effects for each individual - NDVI
  vector[J] i_re_ndvi_s1; // RE effects for each individual - NDVI yday_sin_1 term
  vector[J] i_re_ndvi_s2; // RE effects for each individual - NDVI yday_sin_2 term
  vector[J] i_re_ndvi_c1; // RE effects for each individual - NDVI yday_cos_1 term
  vector[J] i_re_ndvi_c2; // RE effects for each individual - NDVI yday_cos_2 term
  
  vector[J] i_re_canopy; // RE effects for each individual - Canopy cover
  vector[J] i_re_canopy_s1; // RE effects for each individual - canopy yday_sin_1 term
  vector[J] i_re_canopy_s2; // RE effects for each individual - canopy yday_sin_2 term
  vector[J] i_re_canopy_c1; // RE effects for each individual - canopy yday_cos_1 term
  vector[J] i_re_canopy_c2; // RE effects for each individual - canopy yday_cos_2 term
  
  vector[J] i_re_sl; // RE effects for each individual - Step length
  vector[J] i_re_sl_s1; // RE effects for each individual - sl yday_sin_1 term
  vector[J] i_re_sl_s2; // RE effects for each individual - sl yday_sin_2 term
  vector[J] i_re_sl_c1; // RE effects for each individual - sl yday_cos_1 term
  vector[J] i_re_sl_c2; // RE effects for each individual - sl yday_cos_2 term
  
  vector[J] i_re_log_sl; // RE effects for each individual - Log of step length
  vector[J] i_re_log_sl_s1; // RE effects for each individual - log_sl yday_sin_1 term
  vector[J] i_re_log_sl_s2; // RE effects for each individual - log_sl yday_sin_2 term
  vector[J] i_re_log_sl_c1; // RE effects for each individual - log_sl yday_cos_1 term
  vector[J] i_re_log_sl_c2; // RE effects for each individual - log_sl yday_cos_2 term
  
  vector[J] i_re_cos_ta; // RE effects for each individual - Cos of turning angle
  vector[J] i_re_cos_ta_s1; // RE effects for each individual - cos_ta yday_sin_1 term
  vector[J] i_re_cos_ta_s2; // RE effects for each individual - cos_ta yday_sin_2 term
  vector[J] i_re_cos_ta_c1; // RE effects for each individual - cos_ta yday_cos_1 term
  vector[J] i_re_cos_ta_c2; // RE effects for each individual - cos_ta yday_cos_2 term
  
  real<lower = 0.0> sigmaind; // 
  
}


model {

  real mu;
  
  // priors
  // maybe add a prior for sd here
  //sigmaind ~ inv_gamma(0.01, 0.01);  
  // unpopular - half-normal / T instead (lower = 0) - try tight parameters

  sigmaind ~ normal(0.0, 1.0); 
  beta ~ normal(0.0, 1.0);
  a_re ~ normal(0.0, 1000000.0);
  
  i_re_ndvi ~ normal(0.0, sigmaind);
  i_re_ndvi_s1 ~ normal(0.0, sigmaind);
  i_re_ndvi_s2 ~ normal(0.0, sigmaind);
  i_re_ndvi_c1 ~ normal(0.0, sigmaind);
  i_re_ndvi_c2 ~ normal(0.0, sigmaind);
  
  i_re_canopy ~ normal(0.0, sigmaind);
  i_re_canopy_s1 ~ normal(0.0, sigmaind);
  i_re_canopy_s2 ~ normal(0.0, sigmaind);
  i_re_canopy_c1 ~ normal(0.0, sigmaind);
  i_re_canopy_c2 ~ normal(0.0, sigmaind);
    
  i_re_sl ~ normal(0.0, sigmaind);
  i_re_sl_s1 ~ normal(0.0, sigmaind);
  i_re_sl_s2 ~ normal(0.0, sigmaind);
  i_re_sl_c1 ~ normal(0.0, sigmaind);
  i_re_sl_c2 ~ normal(0.0, sigmaind);
    
  i_re_log_sl ~ normal(0.0, sigmaind);
  i_re_log_sl_s1 ~ normal(0.0, sigmaind);
  i_re_log_sl_s2 ~ normal(0.0, sigmaind);
  i_re_log_sl_c1 ~ normal(0.0, sigmaind);
  i_re_log_sl_c2 ~ normal(0.0, sigmaind);
    
  i_re_cos_ta ~ normal(0.0, sigmaind);
  i_re_cos_ta_s1 ~ normal(0.0, sigmaind);
  i_re_cos_ta_s2 ~ normal(0.0, sigmaind);
  i_re_cos_ta_c1 ~ normal(0.0, sigmaind);
  i_re_cos_ta_c2 ~ normal(0.0, sigmaind);
  

  //likelihood


  for (i in 1:N) {

    mu =  a_re[stepid[i]] + 
    
    (beta[1] + i_re_ndvi[indid[i]]) * ndvi[i] + 
    (beta[2] + i_re_ndvi_s1[indid[i]]) * ndvi_s1[i] +
    (beta[3] + i_re_ndvi_s2[indid[i]]) * ndvi_s2[i] +
    (beta[4] + i_re_ndvi_c1[indid[i]]) * ndvi_c1[i] +
    (beta[5] + i_re_ndvi_c2[indid[i]]) * ndvi_c2[i] +
    
    (beta[6] + i_re_canopy[indid[i]]) * canopy[i] + 
    (beta[7] + i_re_canopy_s1[indid[i]]) * canopy_s1[i] + 
    (beta[8] + i_re_canopy_s2[indid[i]]) * canopy_s2[i] + 
    (beta[9] + i_re_canopy_c1[indid[i]]) * canopy_c1[i] + 
    (beta[10] + i_re_canopy_c2[indid[i]]) * canopy_c2[i] + 
    
    (beta[11] + i_re_sl[indid[i]]) * sl[i] + 
    (beta[12] + i_re_sl_s1[indid[i]]) * sl_s1[i] + 
    (beta[13] + i_re_sl_s2[indid[i]]) * sl_s2[i] + 
    (beta[14] + i_re_sl_c1[indid[i]]) * sl_c1[i] + 
    (beta[15] + i_re_sl_c2[indid[i]]) * sl_c2[i] + 
    
    (beta[16] + i_re_log_sl[indid[i]]) * log_sl[i] + 
    (beta[17] + i_re_log_sl_s1[indid[i]]) * log_sl_s1[i] + 
    (beta[18] + i_re_log_sl_s2[indid[i]]) * log_sl_s2[i] + 
    (beta[19] + i_re_log_sl_c1[indid[i]]) * log_sl_c1[i] + 
    (beta[20] + i_re_log_sl_c2[indid[i]]) * log_sl_c2[i] + 
    
    (beta[21] + i_re_cos_ta[indid[i]]) * cos_ta[i] +
    (beta[22] + i_re_cos_ta_s1[indid[i]]) * cos_ta_s1[i] + 
    (beta[23] + i_re_cos_ta_s2[indid[i]]) * cos_ta_s2[i] + 
    (beta[24] + i_re_cos_ta_c1[indid[i]]) * cos_ta_c1[i] + 
    (beta[25] + i_re_cos_ta_c2[indid[i]]) * cos_ta_c2[i];

    y[i] ~ poisson_log(mu);

  }

}
"

```


Stan model with harmonics with matrix parameterisation

```{r}

model <- "data {
  
  int<lower=1> N; // no data points
  int<lower=1> K; // no parameters
  int<lower=1> I; // no steps (over all individuals)
  int<lower=1> J; // no individuals
  
  int<lower=0> y[N]; // response
  
  matrix[N, K] x; // predictor/design matrix
  
}

parameters {




}

model {




}

}
"

```


Stan model with harmonics with QR reparameterisation

```{r}

model <- "data {
  
  int<lower=1> N; // no data points
  int<lower=1> I; // no steps (over all individuals)
  int<lower=1> J; // no individuals
  
  int<lower=0> y[N]; // response
  
  real ndvi[N]; // covariate
  real ndvi_s1[N];
  real ndvi_s2[N];
  real ndvi_c1[N];
  real ndvi_c2[N]; 
    
  real canopy[N]; // covariate
  real canopy_s1[N];
  real canopy_s2[N];
  real canopy_c1[N];
  real canopy_c2[N]; 
  
  real sl[N]; // movement covariate
  real sl_s1[N];
  real sl_s2[N];
  real sl_c1[N];
  real sl_c2[N]; 
  
  real log_sl[N]; // movement covariate
  real log_sl_s1[N];
  real log_sl_s2[N];
  real log_sl_c1[N];
  real log_sl_c2[N]; 
  
  real cos_ta[N]; // movement covariate
  real cos_ta_s1[N];
  real cos_ta_s2[N];
  real cos_ta_c1[N];
  real cos_ta_c2[N]; 
  
  int<lower=1, upper=I> stepid[N]; // step id
  int<lower=1, upper=J> indid[N]; // individual id
  
}

parameters {

  vector[25] beta; // fixed effects
  vector[I] a_re; // RE for steps
  
  vector[J] i_re_ndvi; // RE effects for each individual - NDVI
  vector[J] i_re_ndvi_s1; // RE effects for each individual - NDVI yday_sin_1 term
  vector[J] i_re_ndvi_s2; // RE effects for each individual - NDVI yday_sin_2 term
  vector[J] i_re_ndvi_c1; // RE effects for each individual - NDVI yday_cos_1 term
  vector[J] i_re_ndvi_c2; // RE effects for each individual - NDVI yday_cos_2 term
  
  vector[J] i_re_canopy; // RE effects for each individual - Canopy cover
  vector[J] i_re_canopy_s1; // RE effects for each individual - canopy yday_sin_1 term
  vector[J] i_re_canopy_s2; // RE effects for each individual - canopy yday_sin_2 term
  vector[J] i_re_canopy_c1; // RE effects for each individual - canopy yday_cos_1 term
  vector[J] i_re_canopy_c2; // RE effects for each individual - canopy yday_cos_2 term
  
  vector[J] i_re_sl; // RE effects for each individual - Step length
  vector[J] i_re_sl_s1; // RE effects for each individual - sl yday_sin_1 term
  vector[J] i_re_sl_s2; // RE effects for each individual - sl yday_sin_2 term
  vector[J] i_re_sl_c1; // RE effects for each individual - sl yday_cos_1 term
  vector[J] i_re_sl_c2; // RE effects for each individual - sl yday_cos_2 term
  
  vector[J] i_re_log_sl; // RE effects for each individual - Log of step length
  vector[J] i_re_log_sl_s1; // RE effects for each individual - log_sl yday_sin_1 term
  vector[J] i_re_log_sl_s2; // RE effects for each individual - log_sl yday_sin_2 term
  vector[J] i_re_log_sl_c1; // RE effects for each individual - log_sl yday_cos_1 term
  vector[J] i_re_log_sl_c2; // RE effects for each individual - log_sl yday_cos_2 term
  
  vector[J] i_re_cos_ta; // RE effects for each individual - Cos of turning angle
  vector[J] i_re_cos_ta_s1; // RE effects for each individual - cos_ta yday_sin_1 term
  vector[J] i_re_cos_ta_s2; // RE effects for each individual - cos_ta yday_sin_2 term
  vector[J] i_re_cos_ta_c1; // RE effects for each individual - cos_ta yday_cos_1 term
  vector[J] i_re_cos_ta_c2; // RE effects for each individual - cos_ta yday_cos_2 term
  
  real<lower = 0.0> sigmaind; // 
  
}


model {

  real mu;
  
  // priors
  // maybe add a prior for sd here
  //sigmaind ~ inv_gamma(0.01, 0.01);  
  // unpopular - half-normal / T instead (lower = 0) - try tight parameters

  sigmaind ~ normal(0.0, 1.0); 
  beta ~ normal(0.0, 1.0);
  a_re ~ normal(0.0, 1000000.0);
  
  i_re_ndvi ~ normal(0.0, sigmaind);
  i_re_ndvi_s1 ~ normal(0.0, sigmaind);
  i_re_ndvi_s2 ~ normal(0.0, sigmaind);
  i_re_ndvi_c1 ~ normal(0.0, sigmaind);
  i_re_ndvi_c2 ~ normal(0.0, sigmaind);
  
  i_re_canopy ~ normal(0.0, sigmaind);
  i_re_canopy_s1 ~ normal(0.0, sigmaind);
  i_re_canopy_s2 ~ normal(0.0, sigmaind);
  i_re_canopy_c1 ~ normal(0.0, sigmaind);
  i_re_canopy_c2 ~ normal(0.0, sigmaind);
    
  i_re_sl ~ normal(0.0, sigmaind);
  i_re_sl_s1 ~ normal(0.0, sigmaind);
  i_re_sl_s2 ~ normal(0.0, sigmaind);
  i_re_sl_c1 ~ normal(0.0, sigmaind);
  i_re_sl_c2 ~ normal(0.0, sigmaind);
    
  i_re_log_sl ~ normal(0.0, sigmaind);
  i_re_log_sl_s1 ~ normal(0.0, sigmaind);
  i_re_log_sl_s2 ~ normal(0.0, sigmaind);
  i_re_log_sl_c1 ~ normal(0.0, sigmaind);
  i_re_log_sl_c2 ~ normal(0.0, sigmaind);
    
  i_re_cos_ta ~ normal(0.0, sigmaind);
  i_re_cos_ta_s1 ~ normal(0.0, sigmaind);
  i_re_cos_ta_s2 ~ normal(0.0, sigmaind);
  i_re_cos_ta_c1 ~ normal(0.0, sigmaind);
  i_re_cos_ta_c2 ~ normal(0.0, sigmaind);
  

  //likelihood


  for (i in 1:N) {

    mu =  a_re[stepid[i]] + 
    
    (beta[1] + i_re_ndvi[indid[i]]) * ndvi[i] + 
    (beta[2] + i_re_ndvi_s1[indid[i]]) * ndvi_s1[i] +
    (beta[3] + i_re_ndvi_s2[indid[i]]) * ndvi_s2[i] +
    (beta[4] + i_re_ndvi_c1[indid[i]]) * ndvi_c1[i] +
    (beta[5] + i_re_ndvi_c2[indid[i]]) * ndvi_c2[i] +
    
    (beta[6] + i_re_canopy[indid[i]]) * canopy[i] + 
    (beta[7] + i_re_canopy_s1[indid[i]]) * canopy_s1[i] + 
    (beta[8] + i_re_canopy_s2[indid[i]]) * canopy_s2[i] + 
    (beta[9] + i_re_canopy_c1[indid[i]]) * canopy_c1[i] + 
    (beta[10] + i_re_canopy_c2[indid[i]]) * canopy_c2[i] + 
    
    (beta[11] + i_re_sl[indid[i]]) * sl[i] + 
    (beta[12] + i_re_sl_s1[indid[i]]) * sl_s1[i] + 
    (beta[13] + i_re_sl_s2[indid[i]]) * sl_s2[i] + 
    (beta[14] + i_re_sl_c1[indid[i]]) * sl_c1[i] + 
    (beta[15] + i_re_sl_c2[indid[i]]) * sl_c2[i] + 
    
    (beta[16] + i_re_log_sl[indid[i]]) * log_sl[i] + 
    (beta[17] + i_re_log_sl_s1[indid[i]]) * log_sl_s1[i] + 
    (beta[18] + i_re_log_sl_s2[indid[i]]) * log_sl_s2[i] + 
    (beta[19] + i_re_log_sl_c1[indid[i]]) * log_sl_c1[i] + 
    (beta[20] + i_re_log_sl_c2[indid[i]]) * log_sl_c2[i] + 
    
    (beta[21] + i_re_cos_ta[indid[i]]) * cos_ta[i] +
    (beta[22] + i_re_cos_ta_s1[indid[i]]) * cos_ta_s1[i] + 
    (beta[23] + i_re_cos_ta_s2[indid[i]]) * cos_ta_s2[i] + 
    (beta[24] + i_re_cos_ta_c1[indid[i]]) * cos_ta_c1[i] + 
    (beta[25] + i_re_cos_ta_c2[indid[i]]) * cos_ta_c2[i];

    y[i] ~ poisson_log(mu);

  }

}
"

```


with commented out harmonics

```{r}

model <- "data {
  
  int<lower=1> N; // no data points
  int<lower=1> I; // no steps (over all individuals)
  int<lower=1> J; // no individuals
  
  int<lower=0> y[N]; // response
  
  real ndvi[N]; // covariate
  real ndvi_s1[N];
  //real ndvi_s2[N];
  real ndvi_c1[N];
  //real ndvi_c2[N]; 
    
  real canopy[N]; // covariate
  real canopy_s1[N];
  //real canopy_s2[N];
  real canopy_c1[N];
  //real canopy_c2[N]; 
  
  real sl[N]; // movement covariate
  real sl_s1[N];
  //real sl_s2[N];
  real sl_c1[N];
  //real sl_c2[N]; 
  
  real log_sl[N]; // movement covariate
  real log_sl_s1[N];
  //real log_sl_s2[N];
  real log_sl_c1[N];
  //real log_sl_c2[N]; 
  
  real cos_ta[N]; // movement covariate
  real cos_ta_s1[N];
  //real cos_ta_s2[N];
  real cos_ta_c1[N];
  //real cos_ta_c2[N]; 
  
  int<lower=1, upper=I> stepid[N]; // step id
  int<lower=1, upper=J> indid[N]; // individual id
  
}

parameters {

  vector[25] beta; // fixed effects
  vector[I] a_re; // RE for steps
  
  vector[J] i_re_ndvi; // RE effects for each individual - NDVI
  vector[J] i_re_ndvi_s1; // RE effects for each individual - NDVI yday_sin_1 term
  //vector[J] i_re_ndvi_s2; // RE effects for each individual - NDVI yday_sin_2 term
  vector[J] i_re_ndvi_c1; // RE effects for each individual - NDVI yday_cos_1 term
  //vector[J] i_re_ndvi_c2; // RE effects for each individual - NDVI yday_cos_2 term
  
  vector[J] i_re_canopy; // RE effects for each individual - Canopy cover
  vector[J] i_re_canopy_s1; // RE effects for each individual - canopy yday_sin_1 term
  //vector[J] i_re_canopy_s2; // RE effects for each individual - canopy yday_sin_2 term
  vector[J] i_re_canopy_c1; // RE effects for each individual - canopy yday_cos_1 term
  //vector[J] i_re_canopy_c2; // RE effects for each individual - canopy yday_cos_2 term
  
  vector[J] i_re_sl; // RE effects for each individual - Step length
  vector[J] i_re_sl_s1; // RE effects for each individual - sl yday_sin_1 term
  //vector[J] i_re_sl_s2; // RE effects for each individual - sl yday_sin_2 term
  vector[J] i_re_sl_c1; // RE effects for each individual - sl yday_cos_1 term
  //vector[J] i_re_sl_c2; // RE effects for each individual - sl yday_cos_2 term
  
  vector[J] i_re_log_sl; // RE effects for each individual - Log of step length
  vector[J] i_re_log_sl_s1; // RE effects for each individual - log_sl yday_sin_1 term
  //vector[J] i_re_log_sl_s2; // RE effects for each individual - log_sl yday_sin_2 term
  vector[J] i_re_log_sl_c1; // RE effects for each individual - log_sl yday_cos_1 term
  //vector[J] i_re_log_sl_c2; // RE effects for each individual - log_sl yday_cos_2 term
  
  vector[J] i_re_cos_ta; // RE effects for each individual - Cos of turning angle
  vector[J] i_re_cos_ta_s1; // RE effects for each individual - cos_ta yday_sin_1 term
  //vector[J] i_re_cos_ta_s2; // RE effects for each individual - cos_ta yday_sin_2 term
  vector[J] i_re_cos_ta_c1; // RE effects for each individual - cos_ta yday_cos_1 term
  //vector[J] i_re_cos_ta_c2; // RE effects for each individual - cos_ta yday_cos_2 term
  
  real<lower = 0.0> sigmaind; // 
  
}


model {

  real mu;
  
  // priors
  // maybe add a prior for sd here
  //sigmaind ~ inv_gamma(0.01, 0.01);  
  // unpopular - half-normal / T instead (lower = 0) - try tight parameters

  sigmaind ~ normal(0.0, 10.0); 
  beta ~ normal(0.0, 1.0);
  a_re ~ normal(0.0, 1000000.0);
  i_re_ndvi ~ normal(0.0, sigmaind);
  i_re_ndvi_s1 ~ normal(0.0, sigmaind);
  //i_re_ndvi_s2 ~ normal(0.0, sigmaind);
  i_re_ndvi_c1 ~ normal(0.0, sigmaind);
  //i_re_ndvi_c2 ~ normal(0.0, sigmaind);
  
  i_re_canopy ~ normal(0.0, sigmaind);
  i_re_canopy_s1 ~ normal(0.0, sigmaind);
  //i_re_canopy_s2 ~ normal(0.0, sigmaind);
  i_re_canopy_c1 ~ normal(0.0, sigmaind);
  //i_re_canopy_c2 ~ normal(0.0, sigmaind);
    
  i_re_sl ~ normal(0.0, sigmaind);
  i_re_sl_s1 ~ normal(0.0, sigmaind);
  //i_re_sl_s2 ~ normal(0.0, sigmaind);
  i_re_sl_c1 ~ normal(0.0, sigmaind);
  //i_re_sl_c2 ~ normal(0.0, sigmaind);
    
  i_re_log_sl ~ normal(0.0, sigmaind);
  i_re_log_sl_s1 ~ normal(0.0, sigmaind);
  //i_re_log_sl_s2 ~ normal(0.0, sigmaind);
  i_re_log_sl_c1 ~ normal(0.0, sigmaind);
  //i_re_log_sl_c2 ~ normal(0.0, sigmaind);
    
  i_re_cos_ta ~ normal(0.0, sigmaind);
  i_re_cos_ta_s1 ~ normal(0.0, sigmaind);
  //i_re_cos_ta_s2 ~ normal(0.0, sigmaind);
  i_re_cos_ta_c1 ~ normal(0.0, sigmaind);
  //i_re_cos_ta_c2 ~ normal(0.0, sigmaind);
  

  //likelihood


  for (i in 1:N) {

    mu =  a_re[stepid[i]] + 
    
    (beta[1] + i_re_ndvi[indid[i]]) * ndvi[i] + 
    (beta[2] + i_re_ndvi_s1[indid[i]]) * ndvi_s1[i] + 
    //(beta[3] + i_re_ndvi_s2[indid[i]]) * ndvi_s2[i] + 
    (beta[4] + i_re_ndvi_c1[indid[i]]) * ndvi_c1[i] + 
    //(beta[5] + i_re_ndvi_c2[indid[i]]) * ndvi_c2[i] + 
    
    (beta[6] + i_re_canopy[indid[i]]) * canopy[i] + 
    (beta[7] + i_re_canopy_s1[indid[i]]) * canopy_s1[i] + 
    //(beta[8] + i_re_canopy_s2[indid[i]]) * canopy_s2[i] + 
    (beta[9] + i_re_canopy_c1[indid[i]]) * canopy_c1[i] + 
    //(beta[10] + i_re_canopy_c2[indid[i]]) * canopy_c2[i] + 
    
    (beta[11] + i_re_sl[indid[i]]) * sl[i] + 
    (beta[12] + i_re_sl_s1[indid[i]]) * sl_s1[i] + 
    //(beta[13] + i_re_sl_s2[indid[i]]) * sl_s2[i] + 
    (beta[14] + i_re_sl_c1[indid[i]]) * sl_c1[i] + 
    //(beta[15] + i_re_sl_c2[indid[i]]) * sl_c2[i] + 
    
    (beta[16] + i_re_log_sl[indid[i]]) * log_sl[i] + 
    (beta[17] + i_re_log_sl_s1[indid[i]]) * log_sl_s1[i] + 
    //(beta[18] + i_re_log_sl_s2[indid[i]]) * log_sl_s2[i] + 
    (beta[19] + i_re_log_sl_c1[indid[i]]) * log_sl_c1[i] + 
    //(beta[20] + i_re_log_sl_c2[indid[i]]) * log_sl_c2[i] + 
    
    (beta[21] + i_re_cos_ta[indid[i]]) * cos_ta[i] +
    (beta[22] + i_re_cos_ta_s1[indid[i]]) * cos_ta_s1[i] + 
    //(beta[23] + i_re_cos_ta_s2[indid[i]]) * cos_ta_s2[i] + 
    (beta[24] + i_re_cos_ta_c1[indid[i]]) * cos_ta_c1[i]; // + 
    //(beta[25] + i_re_cos_ta_c2[indid[i]]) * cos_ta_c2[i];

    y[i] ~ poisson_log(mu);

  }

}
"

```


Prior predictive

```{r}



```



Compiling the model

```{r}

# compile the model
tic()
stan_mod <- stan_model(model_code = model)
toc()

stan_mod@model_code

# stancode <- 'data {real y_mean;} parameters {real y;} model {y ~ normal(y_mean,1);}'
# mod <- stan_model(model_code = stancode, verbose = TRUE)

# beep(sound = 2)

```

Preparing data for stan

```{r}

stan_dat <- list(N = nrow(buffalo_subset), 
                 I = length(unique(buffalo_subset$step_aligned)), 
                 J = length(unique(buffalo_subset$id_num)), 
                 y = buffalo_subset$y, 
                 
                 ndvi = buffalo_subset$ndvi_scaled[,1], 
                 ndvi_s1 = buffalo_subset$ndvi_s1, 
                 ndvi_s2 = buffalo_subset$ndvi_s2, 
                 ndvi_c1 = buffalo_subset$ndvi_c1, 
                 ndvi_c2 = buffalo_subset$ndvi_c2,
                 
                 #herby = buffalo_subset$herby_scaled[,1],
                 
                 canopy = buffalo_subset$canopy_scaled[,1],
                 canopy_s1 = buffalo_subset$canopy_s1, 
                 canopy_s2 = buffalo_subset$canopy_s2, 
                 canopy_c1 = buffalo_subset$canopy_c1, 
                 canopy_c2 = buffalo_subset$canopy_c2,
                 
                 sl = buffalo_subset$sl,
                 sl_s1 = buffalo_subset$sl_s1, 
                 sl_s2 = buffalo_subset$sl_s2, 
                 sl_c1 = buffalo_subset$sl_c1, 
                 sl_c2 = buffalo_subset$sl_c2,
                 
                 log_sl = buffalo_subset$log_sl,
                 log_sl_s1 = buffalo_subset$log_sl_s1, 
                 log_sl_s2 = buffalo_subset$log_sl_s2, 
                 log_sl_c1 = buffalo_subset$log_sl_c1, 
                 log_sl_c2 = buffalo_subset$log_sl_c2,
                 
                 cos_ta = buffalo_subset$cos_ta,
                 cos_ta_s1 = buffalo_subset$cos_ta_s1, 
                 cos_ta_s2 = buffalo_subset$cos_ta_s2, 
                 cos_ta_c1 = buffalo_subset$cos_ta_c1, 
                 cos_ta_c2 = buffalo_subset$cos_ta_c2,
                 
                 stepid = as.numeric(factor(buffalo_subset$step_aligned)), 
                 indid = buffalo_subset$id_num)

```



```{r}

tic()
res_stan_mvmt <- sampling(stan_mod, stan_dat, cores = 4, chains = 2, iter = 100)
toc()

# system("killall R")
# interrupt(res_stan_mvmt)

beep(sound = 2)

```


```{r}

model <- res_stan_mvmt

summary(model)$summary[1:10, ]
tail(summary(model)$summary)
traceplot(model,pars=c("beta[1]", "beta[2]", "beta[3]", "a_re[1]", "a_re[2]", "a_re[3]"))

# print(res_stan)
plot(model, pars = "beta")
plot(model, pars = "beta", plotfun = "stan_hist")
# extract(model, pars = "beta")

# check diagnostics and samples using the shiny stan app
launch_shinystan(model)

```


For checking with conditional logistic regression

```{r}

clogit_model <- buffalo_subset %>% 
  fit_clogit(case_ ~ 
               ndvi_temporal +
               # ndwi_temporal +
               # #veg_woody +
               # veg_herby +
               # canopy_cover +
               # DEM_H_end +
               # slope_end +
               #WOFS25_dist +
               #WOFS50_dist +
               #WOFS80_dist +
               log_sl_ +
               cos_ta_ +
               # ndvi_temporal:cos_ta_ + 
               # ndvi_temporal:log_sl_ +
               strata(step_id_))


clogit_model
summary(clogit_model)
AIC(clogit_model)

```


### brms

Generate stan code using brms

```{r}

formula_qr <- brmsformula(formula = 
                            
                            y ~ -1 +
                            
                            ndvi_scaled +
                            # ndvi_2 +
                            # ndvi_s1 +
                            # ndvi_s2 +
                            # ndvi_c1 +
                            # ndvi_c2 +
                            
                            canopy_scaled +
                            # canopy_2 +
                            # canopy_s1 +
                            # canopy_s2 +
                            # canopy_c1 +
                            # canopy_c2 +
                            
                            sl_scaled +
                            log_sl +
                            cos_ta +
                            
                            (1 | step_id) +
                            (1 | id),# +
                            # (0 + ndvi_scaled)
                            # (0 + ndvi_scaled | id) +
                            # (0 + ndvi_s1 | id) +
                            # (0 + ndvi_s2 | id) +
                            # (0 + ndvi_c1 | id) +
                            # (0 + ndvi_c2 | id) +
                            # (0 + ndvi_2 | id) +
                            # (0 + canopy_scaled | id) +
                            # (0 + canopy_s1 | id) +
                            # (0 + canopy_s2 | id) +
                            # (0 + canopy_c1 | id), # +
                            # (0 + canopy_c2 | id),
                            # (0 + canopy_2 | id),
                            # (0 + sl_scaled | id) +
                            # (0 + log_sl | id) +
                            # (0 + cos_ta | id),
                            decomp = "QR",
                            family = poisson(link = log))
                            
                    
                  
                            # y ~ -1 +
                            # ndvi_scaled +
                            # sl +
                            # log_sl +
                            # cos_ta
                            # (1 | id / step_id)
                            # ,
                            # family = poisson(link = log),
                            # decomp = "QR")

# setting the priors
brms_priors <- c(set_prior("normal(0,1)", class = "b"),
                 set_prior("normal(0,1)", class = "sd")
                 # set_prior("constant(1000000)", class = "sd", coef = "Intercept", group = "step_id"),
                 # set_prior("normal(0,1000000)", class = "sd", group = "step_id")
                 )

get_prior(formula_qr,
          data = buffalo_subset)

brms_stancode <- make_stancode(formula_qr,
              data = buffalo_subset,
              prior = brms_priors)

brms_stancode

brms_standata <- make_standata(formula_qr,
              data = buffalo_subset,
              prior = brms_priors)

unique(brms_standata$J_2)

# brms_standata

```


```{r}

brms_stancode_edited <- "data {

  int<lower=1> N;  // total number of observations
  int Y[N];  // response variable
  int<lower=1> K;  // number of population-level effects
  matrix[N, K] X;  // population-level design matrix
  // data for group-level effects of ID 1
  int<lower=1> N_1;  // number of grouping levels
  int<lower=1> M_1;  // number of coefficients per level
  int<lower=1> J_1[N];  // grouping indicator per observation
  // group-level predictor values
  vector[N] Z_1_1;
  // data for group-level effects of ID 2
  int<lower=1> N_2;  // number of grouping levels
  int<lower=1> M_2;  // number of coefficients per level
  int<lower=1> J_2[N];  // grouping indicator per observation
  // group-level predictor values
  vector[N] Z_2_1;
  int prior_only;  // should the likelihood be ignored?
}

transformed data {
  // matrices for QR decomposition
  matrix[N, K] XQ;
  matrix[K, K] XR;
  matrix[K, K] XR_inv;
  // compute and scale QR decomposition
  XQ = qr_thin_Q(X) * sqrt(N - 1);
  XR = qr_thin_R(X) / sqrt(N - 1);
  XR_inv = inverse(XR);
}

parameters {
  vector[K] bQ;  // regression coefficients at QR scale
  vector<lower=0>[M_1] sd_1;  // group-level standard deviations
  vector[N_1] z_1[M_1];  // standardized group-level effects
  vector<lower=0>[M_2] sd_2;  // group-level standard deviations
  // vector[N_2] z_2[M_2];  // standardized group-level effects
}

transformed parameters {
  vector[N_1] r_1_1;  // actual group-level effects
  vector[N_2] r_2_1;  // actual group-level effects
  real lprior = 0;  // prior contributions to the log posterior
  r_1_1 = (sd_1[1] * (z_1[1]));
  
  // changed code
  // r_2_1 = (sd_2[1] * (z_2[1])); // code removed
  r_2_1 = (100 * (z_2[1]));
  
  lprior += normal_lpdf(bQ | 0,1);
  lprior += normal_lpdf(sd_1 | 0,1)
    - 1 * normal_lccdf(0 | 0,1);
  lprior += normal_lpdf(sd_2 | 0,1)
    - 1 * normal_lccdf(0 | 0,1);
}

model {
  // likelihood including constants
  
  if (!prior_only) {
    // initialize linear predictor term
    vector[N] mu = rep_vector(0.0, N);
    for (n in 1:N) {
      // add more terms to the linear predictor
      mu[n] += r_1_1[J_1[n]] * Z_1_1[n] + r_2_1[J_2[n]] * Z_2_1[n];
    }
    
    target += poisson_log_glm_lpmf(Y | XQ, mu, bQ);
  }
  
  // priors including constants
  target += lprior;
  target += std_normal_lpdf(z_1[1]);
  target += std_normal_lpdf(z_2[1]);
}

generated quantities {
  // obtain the actual coefficients
  vector[K] b = XR_inv * bQ;
}

"

```

Fit the model

```{r}

tic()

brms_mod3 <- brm(formula = formula_qr,
                 data = buffalo_subset,
                 prior = brms_priors,
                 # warmup = 100,
                 init = "0",
                 # iter = 1000, chains = 2, algorithm =  "sampling"
                 iter = 100000, algorithm =  "meanfield" # variational inference
                # algorithm = "fixed_param"
              )

toc()

```

Model outputs

```{r}

summary(brms_mod, waic = TRUE)
plot(brms_mod, ask = FALSE)

summary(brms_mod2, waic = TRUE)
plot(brms_mod2, ask = FALSE)

# launch_shinystan(brms_mod)
# 
# post_pred_subset <- posterior_predict(brms_mod, 
#                                       resp = "ndvi_temporal",
#                                       ndraws = 100)

```

Using the brms stan code directly in stan so I can use the optimisation function as well

```{r}

tic()
brms_stan_mod <- stan_model(model_code = brms_stancode_edited)
toc()

tic()
brms_stan_optim <- sampling(brms_stan_mod, brms_standata)
toc()

tic()
brms_stan_optim <- optimizing(brms_stan_mod, brms_standata)
toc()

head(brms_stan_optim$par, 50)
tail(brms_stan_optim$par, 50)

```





```{r}

formula_final <- case_ ~

               ndvi_temporal +
               month_s1:ndvi_temporal +
               month_s2:ndvi_temporal +
               month_c1:ndvi_temporal +
               month_c2:ndvi_temporal +

               WOFS05_dist_scaled +
               month_s1:WOFS05_dist_scaled +
               month_s2:WOFS05_dist_scaled +
               month_c1:WOFS05_dist_scaled +
               month_c2:WOFS05_dist_scaled +

               I(WOFS05_dist_scaled^2) +
               month_s1:I(WOFS05_dist_scaled^2) +
               month_s2:I(WOFS05_dist_scaled^2) +
               month_c1:I(WOFS05_dist_scaled^2) +
               month_c2:I(WOFS05_dist_scaled^2) +

               # elev_scaled +
               # month_s1:elev_scaled +
               # month_s2:elev_scaled +
               # month_c1:elev_scaled +
               # month_c2:elev_scaled +
               # 
               # I(elev_scaled^2) +
               # month_s1:I(elev_scaled^2) +
               # month_s2:I(elev_scaled^2) +
               # month_c1:I(elev_scaled^2) +
               # month_c2:I(elev_scaled^2) +

               slope_scaled +
               month_s1:slope_scaled +
               month_s2:slope_scaled +
               month_c1:slope_scaled +
               month_c2:slope_scaled +

               veg_herby +
                month_s1:veg_herby +
               month_s2:veg_herby +
               month_c1:veg_herby +
               month_c2:veg_herby +

               canopy_01 +
               month_s1:canopy_01 +
               month_s2:canopy_01 +
               month_c1:canopy_01 +
               month_c2:canopy_01 +

               log_sl_ +
               month_s1:log_sl_ +
               month_s2:log_sl_ +
               month_c1:log_sl_ +
               month_c2:log_sl_ +

               cos_ta_ +
               month_s1:cos_ta_ +
               month_s2:cos_ta_ +
               month_c1:cos_ta_ +
               month_c2:cos_ta_ +

               strata(step_id_)

```

